### æ•°æ®é¢„å¤„ç†
>>> scaler = StandardScaler()
>>> scaled_train_data = scaler.fit_transform(X)
æ ‡å‡†åŒ–çš„è¿‡ç¨‹æ˜¯å°†ç‰¹å¾çš„å€¼è½¬æ¢ä¸ºå‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1 çš„åˆ†å¸ƒã€‚
fitï¼šè®¡ç®—è®­ç»ƒé›†ä¸­æ¯åˆ—çš„å‡å€¼ (Î¼) å’Œæ ‡å‡†å·® (Ïƒ)ï¼Œå¹¶å°†è¿™äº›å‚æ•°ä¿å­˜åˆ° scaler å¯¹è±¡ä¸­ã€‚
transformï¼šä½¿ç”¨è®¡ç®—å‡ºçš„å‡å€¼å’Œæ ‡å‡†å·®å¯¹è®­ç»ƒé›†çš„æ¯ä¸ªå€¼è¿›è¡Œæ ‡å‡†åŒ–ï¼šð‘§ = ï¼ˆð‘¥ âˆ’ ðœ‡ï¼‰ /ðœŽ

>>> scaled_test=scaler.transform(df_test)
â€‹å¯¹æµ‹è¯•é›†è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä½†ä½¿ç”¨çš„æ˜¯è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚æµ‹è¯•é›†çš„æ ‡å‡†åŒ–ä½¿ç”¨è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œç¡®ä¿è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åœ¨ç›¸åŒçš„å°ºåº¦ä¸‹è¿›è¡Œæ¯”è¾ƒã€‚

åœ¨å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆæˆ–å…¶ä»–ç±»ä¼¼çš„é¢„å¤„ç†æ“ä½œï¼‰æ—¶ï¼Œå¯¹ è®­ç»ƒé›† ä½¿ç”¨ fit_transformï¼Œè€Œå¯¹ æµ‹è¯•é›† ä»…ä½¿ç”¨ transformï¼Œ
è¿™æ˜¯å› ä¸ºåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæµ‹è¯•é›†å¿…é¡»ä¸Žè®­ç»ƒé›†ä¿æŒä¸€è‡´çš„æ ‡å‡†åŒ–å‚æ•°ï¼Œä¸èƒ½å•ç‹¬é‡æ–°æ‹Ÿåˆæµ‹è¯•é›†ã€‚
1. é¿å…æ•°æ®æ³„éœ²ï¼ˆData Leakageï¼‰
æ•°æ®æ³„éœ²æ˜¯æŒ‡æ¨¡åž‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ­£ç¡®åœ°åˆ©ç”¨äº†æµ‹è¯•é›†ä¸­çš„ä¿¡æ¯ï¼Œè¿™ä¼šå¯¼è‡´æ¨¡åž‹çš„è¡¨çŽ°è¢«é«˜ä¼°ï¼Œå¹¶ä¸”æ— æ³•æ³›åŒ–åˆ°æœªè§è¿‡çš„æ•°æ®ã€‚
å¦‚æžœå¯¹æµ‹è¯•é›†ä½¿ç”¨ fit_transformï¼Œæ¨¡åž‹ä¼šä»Žæµ‹è¯•é›†ä¸­æå–ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚å‡å€¼å’Œæ ‡å‡†å·®ï¼‰ï¼Œè¿™ç­‰åŒäºŽåœ¨è®­ç»ƒé˜¶æ®µæå‰çŸ¥é“äº†æµ‹è¯•æ•°æ®çš„ç‰¹æ€§ï¼Œæ˜¯ä¸€ç§æ•°æ®æ³„éœ²ã€‚
è®­ç»ƒæ•°æ®æ˜¯ç”¨æ¥è®©æ¨¡åž‹å­¦ä¹ çš„ï¼Œè€Œæµ‹è¯•æ•°æ®æ˜¯ç”¨æ¥éªŒè¯æ¨¡åž‹æ•ˆæžœçš„ã€‚
æ ‡å‡†åŒ–çš„ç›®çš„æ˜¯å°†ç‰¹å¾å€¼è°ƒæ•´åˆ°ç›¸åŒçš„å°ºåº¦ï¼Œä»¥ä¾¿æ¨¡åž‹æ›´å¥½åœ°å­¦ä¹ ã€‚å¦‚æžœå¯¹æµ‹è¯•é›†å•ç‹¬é‡æ–°æ‹Ÿåˆæ ‡å‡†åŒ–ï¼ˆfit_transformï¼‰ï¼Œå®ƒå¯èƒ½ä¸Žè®­ç»ƒé›†çš„æ ‡å‡†åŒ–èŒƒå›´ä¸ä¸€è‡´ï¼Œä»Žè€Œå¯¼è‡´æ¨¡åž‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨çŽ°å¤±çœŸã€‚

###KæŠ˜äº¤å‰éªŒè¯
>>> kf=KFold(n_splits=n_splits,shuffle=True,random_state=42)
  shuffle=True æŒ‡å®šæ˜¯å¦åœ¨åˆ†å‰²å‰å¯¹æ•°æ®è¿›è¡Œéšæœºæ‰“ä¹±ã€‚ å¦‚æžœè®¾ç½®ä¸º Trueï¼Œæ•°æ®ä¼šåœ¨åˆ†å‰²å‰éšæœºæ‰“ä¹±ï¼Œé¿å…æ•°æ®é¡ºåºå¯¹ç»“æžœäº§ç”Ÿå½±å“ï¼ˆå¦‚æ—¶é—´åºåˆ—æ•°æ®ï¼‰ã€‚
  random_state=42 è®¾ç½®éšæœºç§å­ï¼Œç”¨äºŽç¡®ä¿æ•°æ®çš„éšæœºæ‰“ä¹±æ˜¯å¯å¤çŽ°çš„ã€‚ åœ¨è®¾ç½®ç›¸åŒçš„ random_state æ—¶ï¼Œæ¯æ¬¡è¿è¡Œä»£ç éƒ½èƒ½äº§ç”Ÿç›¸åŒçš„éšæœºç»“æžœã€‚

>>> kf.split(scaled_train_data, y)
  X (å¿…é¡»å‚æ•°) é€šå¸¸ä¸ºç‰¹å¾æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_samples, n_features)ï¼Œæˆ–ä¸€ç»´æ•°ç»„ (n_samples,)
  yç›®æ ‡å˜é‡, å¦‚æžœæä¾›ï¼ŒKFold ä¸ä¼šç›´æŽ¥ç”¨å®ƒåˆ’åˆ†æ•°æ®ï¼Œè€Œæ˜¯ä¸Ž X ä¿æŒç´¢å¼•å¯¹åº”å…³ç³»
  æ¯æ¬¡è°ƒç”¨éƒ½ä¼šç”Ÿæˆä¸€ç»„è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç´¢å¼•ï¼Œå½¢çŠ¶ä¸º (train_idx, test_idx)ã€‚
  train_idx å’Œ test_idx åˆ†åˆ«æ˜¯è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ ·æœ¬ç´¢å¼•ã€‚

>>> lgbm_model = LGBMRegressor(**lgb_params)
>>> lgbm_model.fit(
    X_train, y_train, 
    eval_set=[(X_val, y_val)], 
    eval_metric='rmse',
    # early_stopping_rounds=10,
    # verbose=False
)
    eval_set=[(X_val, y_val)] æä¾›éªŒè¯é›† X_val å’Œå¯¹åº”çš„æ ‡ç­¾ y_valï¼Œç”¨äºŽåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¯„ä¼°æ¨¡åž‹æ€§èƒ½ã€‚
    eval_metric='rmse', æŒ‡å®šç”¨äºŽè¯„ä¼°æ¨¡åž‹æ€§èƒ½çš„æŒ‡æ ‡,rmse è¡¨ç¤ºå‡æ–¹æ ¹è¯¯å·®ï¼ˆRoot Mean Squared Errorï¼‰ï¼Œé€‚ç”¨äºŽå›žå½’ä»»åŠ¡ã€‚
  early_stopping_rounds=10 (æ³¨é‡ŠæŽ‰ï¼Œä½†è¯´æ˜Žå…¶ä½œç”¨) å¦‚æžœåœ¨è¿žç»­ 10 æ¬¡è¿­ä»£ä¸­ï¼ŒéªŒè¯é›†çš„æ€§èƒ½æŒ‡æ ‡æ²¡æœ‰æ˜¾è‘—æå‡ï¼Œæ¨¡åž‹ä¼šæå‰åœæ­¢è®­ç»ƒã€‚ å¯ä»¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹å¹¶å‡å°‘è¿‡æ‹Ÿåˆçš„é£Žé™©ã€‚
  æ³¨æ„:å¿…é¡»æä¾›éªŒè¯é›†ï¼ˆeval_setï¼‰æ‰èƒ½å¯ç”¨ early_stopping_roundsã€‚å½“è¾¾åˆ°åœæ­¢æ¡ä»¶æ—¶ï¼Œæ¨¡åž‹ä¼šè‡ªåŠ¨æ¢å¤åˆ°æ€§èƒ½æœ€ä½³çš„è¿­ä»£ã€‚
  verbose=False (æ³¨é‡ŠæŽ‰ï¼Œä½†è¯´æ˜Žå…¶ä½œç”¨) æŽ§åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ—¥å¿—è¾“å‡ºã€‚
  verbose=Trueï¼ˆé»˜è®¤ï¼‰:æ¯éš”ä¸€å®šçš„è¿­ä»£æ¬¡æ•°æ‰“å°ä¸€æ¬¡è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ€§èƒ½æŒ‡æ ‡ã€‚
  verbose=False: ç¦æ­¢æ—¥å¿—è¾“å‡ºï¼ˆæ›´é€‚åˆåœ¨è°ƒå‚æˆ–å¤§é‡è¿­ä»£æ—¶ä½¿ç”¨ï¼‰ã€‚

>>> lgbm_fold_preds=lgbm_model.predict(X_val)
é¢„æµ‹è®­ç»ƒé›†ä¸­çš„éªŒè¯é›†

>>> fold_rmse=np.sqrt(mean_squared_error(y_val,lgbm_fold_preds))
è®¡ç®—æ–¹å·®
