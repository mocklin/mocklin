### 数据预处理
>>> scaler = StandardScaler()
>>> scaled_train_data = scaler.fit_transform(X)
标准化的过程是将特征的值转换为均值为 0，标准差为 1 的分布。
fit：计算训练集中每列的均值 (μ) 和标准差 (σ)，并将这些参数保存到 scaler 对象中。
transform：使用计算出的均值和标准差对训练集的每个值进行标准化：𝑧 = （𝑥 − 𝜇） /𝜎

>>> scaled_test=scaler.transform(df_test)
​对测试集进行标准化，但使用的是训练集的均值和标准差。测试集的标准化使用训练集的均值和标准差，确保训练和测试数据在相同的尺度下进行比较。

在对数据进行标准化（或其他类似的预处理操作）时，对 训练集 使用 fit_transform，而对 测试集 仅使用 transform，
这是因为在机器学习中，测试集必须与训练集保持一致的标准化参数，不能单独重新拟合测试集。
1. 避免数据泄露（Data Leakage）
数据泄露是指模型在训练过程中不正确地利用了测试集中的信息，这会导致模型的表现被高估，并且无法泛化到未见过的数据。
如果对测试集使用 fit_transform，模型会从测试集中提取统计信息（如均值和标准差），这等同于在训练阶段提前知道了测试数据的特性，是一种数据泄露。
训练数据是用来让模型学习的，而测试数据是用来验证模型效果的。
标准化的目的是将特征值调整到相同的尺度，以便模型更好地学习。如果对测试集单独重新拟合标准化（fit_transform），它可能与训练集的标准化范围不一致，从而导致模型在测试集上的表现失真。

###K折交叉验证
>>> kf=KFold(n_splits=n_splits,shuffle=True,random_state=42)
  shuffle=True 指定是否在分割前对数据进行随机打乱。 如果设置为 True，数据会在分割前随机打乱，避免数据顺序对结果产生影响（如时间序列数据）。
  random_state=42 设置随机种子，用于确保数据的随机打乱是可复现的。 在设置相同的 random_state 时，每次运行代码都能产生相同的随机结果。

>>> kf.split(scaled_train_data, y)
  X (必须参数) 通常为特征数据，形状为 (n_samples, n_features)，或一维数组 (n_samples,)
  y目标变量, 如果提供，KFold 不会直接用它划分数据，而是与 X 保持索引对应关系
  每次调用都会生成一组训练集和验证集的索引，形状为 (train_idx, test_idx)。
  train_idx 和 test_idx 分别是训练集和验证集的样本索引。

>>> lgbm_model = LGBMRegressor(**lgb_params)
>>> lgbm_model.fit(
    X_train, y_train, 
    eval_set=[(X_val, y_val)], 
    eval_metric='rmse',
    # early_stopping_rounds=10,
    # verbose=False
)
    eval_set=[(X_val, y_val)] 提供验证集 X_val 和对应的标签 y_val，用于在训练过程中评估模型性能。
    eval_metric='rmse', 指定用于评估模型性能的指标,rmse 表示均方根误差（Root Mean Squared Error），适用于回归任务。
  early_stopping_rounds=10 (注释掉，但说明其作用) 如果在连续 10 次迭代中，验证集的性能指标没有显著提升，模型会提前停止训练。 可以加速训练过程并减少过拟合的风险。
  注意:必须提供验证集（eval_set）才能启用 early_stopping_rounds。当达到停止条件时，模型会自动恢复到性能最佳的迭代。
  verbose=False (注释掉，但说明其作用) 控制训练过程中的日志输出。
  verbose=True（默认）:每隔一定的迭代次数打印一次训练集和验证集的性能指标。
  verbose=False: 禁止日志输出（更适合在调参或大量迭代时使用）。

>>> lgbm_fold_preds=lgbm_model.predict(X_val)
预测训练集中的验证集

>>> fold_rmse=np.sqrt(mean_squared_error(y_val,lgbm_fold_preds))
计算方差
